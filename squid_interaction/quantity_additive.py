import os

import mavenn
import numpy as np
import pandas as pd
import squid
import tensorflow as tf
import tqdm

from utils import QuantityEnsembler, SquidWrapper, corr

gpus = tf.config.experimental.list_physical_devices("GPU")
for gpu in gpus:
    tf.config.experimental.set_memory_growth(gpu, True)

model_path = "../clipnet/clipnet_models"
model_list = os.listdir(model_path)
print(model_list)

# Load and wrap models
models_ = [
    SquidWrapper(
        tf.keras.models.load_model(
            os.path.join(model_path, m), custom_objects={"corr": corr}
        )
    )
    for m in tqdm.tqdm(model_list)
]
models = QuantityEnsembler(models_)

# Sequence of the IRF4 promoter in hg38. 2114 sequence taken for compatibility with
# ProCapNet and the PyTorch implementation of CLIPNET. We analyze the TF version
# of CLIPNET here, so we trim to just the middle 1kb
# >irf4_prom range=chr6:390663-392776 5'pad=0 3'pad=0 strand=+ repeatMasking=none
sequences = {
    "EH38E2695794": "CGAGATGACATCAGCTTCTAAACATAGCAAGCACCGCACCCCAACTCCATGGGCTGCGGGGGTGGGGAGGGAGTGGGGGAGGCGGGTGCTGCTGTCCCCGGGCGGGGCGTGGCGGGCAGGCCGGCCAGGCTGTGCGGGAGGAGATGACTTTGCAGGAATTGCGCTCCCAGAGTTTGCCGGCAGATCTCTCCCGCGATGGCCCGGCCAAGGGGTTAGGAAACATTCCTGCCATTCCGTGCTCTCCCCTACCCCACAAGAACCACACGCACGCACACACGCACTCTTGGATCGAATGTGCCTTTATTTATAAATCAATCCAGCCCCAGCCCAGGTTCGGTCCGGTCCCGGGAGCACCTGCGCCCCGCGTCTGCCTTCAGGCTAAGCCTGCGAGGGGTTCGGTGTGGCCCTCCCAGTGAGTCAGAATGGGCTGTGTTTCCTGTGGTTGTTGTGGAACAGTTTGTCCTTTTTACTCTCCGCCCCCCCCGCCCCGTCTCCACCCCCTTGGTAAATATAGCGCTCACGTTTCATCATCTCTTTGTCCAACGAGTGCCAGACACCCCGGCCCGCGGCCCCCGCCGCCTCCCTCCTCCTCTCCGCTCGGTTACCTCGCATAACCTCGCGCGGGCAGGCACCGGGCAGCAGCTCTCCCCGCGGCCGCGCCCGCCCGGCACCCAGCGCTTCCCGCCGCAGCACACCCCCAACCCATTCTCCCCTCCCCTTCTTCCAGTTCCCCCTTCTGTACGGCCCCCATGCTCTTGTCCCACCCCCTCTACTCGGCGTCCGGGTACTGGGTCGAGACGTGTGTAGGTGTAGGGAGGTGGATAGCCCTTTTCCGAGCCGTAGGCGTCACCCCTACGCCCAGGCCCAGGCCCAGTGCTGGATCCTGCACTTTCCCAACCTCCCCCTCCCAAGTTCCAAGGTTGCCCTCTGTTCCCCTCCCAAGCGCAGGTGACAAGCTGCTGAGACAGTGTCTGATTCACCGACAGCTGAACCAGCTACT",
    "rpl35_prom": "CACCTTCAGGTCGTCCAGCTGTTTCAGCAGCTCCTCCTTCTTCTTCCCGCGAAGATCTCGAGCCTTGATCTTGGCCTGCGCGCAAGAGAGAGTGTGCCTCAGCCAGGCCGCGGGGCCATATCCCCTTCACCTGCGTGGCCAGCCCCCAAAGGCGCGCGACTCGCCATCGACTACGAGTGCGCCGGAGCCCCAACCAGGGCTCAGGACAGTCTCCCTCGCCGGCCGTGCCTTGGGCAGAGTAACCCAGGCCCGGGCCGCGCGCCTCTCCCGGCGCCAAGCGAAGAGGCGGGTTGTGGTGGCGCCAGACCATTCTGCGCGGCGCCCCACAGGCCTAGGTGGCAGATAGAATCCGCGGGCTCAGCCCGCACCGCCTTCCCCAACCCCCGCGCCTCACAGCGCTCGGATGGCGCCCGATTCCGCAGCTCTCACCATTGCTGCACAAGCCGCCAACGCCGCCGCCCGCTCCGAGGGAAAGAGGAAGTAGGCGGGGCTGACCTCCGCAACTACTGCCGGGTGGCGGCGGGCGCGGCCAATGGCGCCGCAGCGGGGGAGCCCCGGCTCCGCCTCATCTCCCCCGCCCCCGAGGAACGCCGTGGTACTGCCCGCCCCGCCTGGTAGGGCCGGAGCCCCGCCTTGTAGTGCTCGCCTCATTCACGGCACCCCTGATAGCGAGGTCGGCGTCACGGTGTAGGCGCGCAGTTGGGGAAACCGAGGCCCAACGTGGGCGGCAGCTACCAGAGATGGCACACGGAGGACTCAAATTCGTCCATTCAGTCATTCGTTCATTCATTCCTTCGGGAAACCTTGCAGATCTCCCAATCTGGGCAACTCTGAGCTGGGCGCCAGTAGTCTGGGGGTGCTGACGGGAGGAGGGGCCAGAGTTTTCAAAGACGATTAACCGAGGCTCACGTCGCGGAGGAATTTAAAGCGCGAGATGGACGGGAGGGGCGGGCTCAGGCAGTTATAATCCAACTCCATAAAGGTTCTGGGGAGGCAGTAT",
    "ints6_prom": "GATAGTTGAGAGGAAACTCCCCAGACCCAGTGCTCCCCGTCGTACCCCCGCCTCCGCCTCCTCCTGCCTGCCTGCCCGCTGGGGCGGGCGCCCAGCCGTCTGTCTGTCGGTTCGTCCCCCCCGCCTCGGGGGTCCCGTCCCCGCTCCCGGCCCCTGTGTGTGTCCCAGCGGGAGACGGGCCTGGCTCCCCACCCCACCCCCGGTACAGGAGTGGGGACCTGGGAGCTGGCGAAGAGGGGAGTGGGCTGAGGGAAGATTGGCCCTGGGGCTGTTGGGAGAAGTTTCAGGGACTCCCTCCGCACCCCGGCGGTGTCACCACTTTCTCAGCCCCTCTCGCTACTGAAGCGCTTTTCTCTCTCACACTCCGGTTTTAACTCGGGCAGGGGCTGCGGAGGCTCCGCCCCTGACACGTCCCCGAGCCACGTGATACACCGCCTCGCCGTTCTACTGGTCAGGCCCTATCCTTTCATTAGCATATTTAAACAGCTCAGGGGCGGGGGAAGCTTGTAGGCCGGCTCCGGGGACAGTTATTGAGCACGCGCAGAGGCGGGGCGTCGGGTGCGCGCGAGCGGGCGGGCGGGCCGACCCGGAGGCGGGCTTCGGGAAGGGGCGGGGCCGGACTGCGGAAGGACCGCGAGGTGGGGGCGGGGGCCGCGTCCGCGCGCGCGGGGCGGCCGCGGCGGTGAGCCTGCGCGTCAGGGCCGCCGGCCTCTCCTTGGCTGTTGGAGGTGATAGGGGTCGAGGGGAGGGAAAAAGGGGCTGGCGTCAGCCGCCCCTGTGAGGTGGCCGTAGCGTGGACGAGTAAGAAGGGTTGAGTAAAGTGGACAAACACCTGGTTAGGAGAAGAGGGCAGGCCCGCAGCCGCCCTCCGGAGGAGGACTCGGGGCCTCGCGGGCGCCGGAGGAGGTTCCTGGGCCTCGGAGGGCCGCCCCGGCGCGCCGCCCCGGCGCGAGCGGGCGCGGGCGGGGGAGGGGAAGTGAGAGGTTGTTTATGACCGGGG",
    "EH38E2107427": "GGGTCCTTGTAATCTGCCAGGATAGAAATCAAGAGCGATCACCAGACATAGCAGCAAAGAGAAAGAGCTTTATTTAGCTTGTGCACGAGGGAAGTCAGCAACATGAAAGGAAGAGGGCAGGCTGCTCCCCAGGGGAGTGTGTGGGTTAGATTTCTAGGGCCTTTCTATGGAGAGGGGTTTCAGGGTTCCTCCAGGGGAGTGTGTGGGTTAGATTTCCAGGGCCTTTCTATAGGGAAGGGTTTCCCCAGGGGAGCGTGGGGGTCAGATTTCCAGGGACTTTCTGTAGGGAAGGATTTTGCCAGGGCATGTATAGGAGGAGGGGTTTCTCTAGCACTTGCACAGTGGCTCAACACACTTTTTCAAACATTGCATGTAACATCAGCATTTTAAATCTCCGTGCTTGGGCACGATTTGCAGCATTAAAATGAGGAAGAGGGTAAGTTGAAGTTTAAGTCTAACTGCACATGCGGGGCCCCAGGGAAGTCCCTAGCCCCCTAGAGCAGGAACTCGTGGTGAATAGTTTCCTGGGTCTTTGGCTGCTGATTGGCTGGAAGTCAGGTGAGCTACAGTCTGATAAGGGGTTTTTGTACTTTTTCTCTAAACCACATCAAAACCAGGAAACCAGTCAGCCTGCCTGTCTCACGAGCCCCTATTTCCTGTTGTAGATGGTGACCAGCTTGTCCTGGTTTGCTTGGAACTGTCCTGGTTTTCAAATGTAAGGTTCCACATCCTGGGCACCCCCCAGTCCTGGGCAAACCAGAATGGCTGGCCAGACTGTTGCTGTGACTGGAGTGGGGCATACCCTGCCTGCTTTTTTCTGGGCCTTACCTGCTAAGTGGTGTCCAAGGAGAGGCCCTGGGGGTCTGGGTGTGGGATGGGCTGGTGACTCGTCCCTCTGTGCCCTTCCCACCCACTCTTGCCCTCAGTGCTGGTGCCCACCTGGCATCCCGGACACCATCCAGGGCACCCTGGCTGGATGGCCTGTCTTCATGGGCCATGG",
    "ifnar2_prom": "CCTATCCCGAAACACGTTGATCAGTGGGGGGTCGAGGGAAGGGTAGGAGTATGGAGAAGAGACCCGCGGAGAAGAGGGGAGAATCTACAACGGATAATGTTGTAGATATTTACAACATTTACTCAATGGTAGGTATTTTTATCCTCGTTTTACTAGTTGGAGAATTATATCATGCAGGTTTATACAATTAACAAGTGGGGGAGCCAGGAGAGAACCCATTCACTCTTTAGTTCATTCATTCATTCAGTCAGTCAACACATCTTTGGGTGTCTTCTAAATGCCAGGCACTATTCTAACCCCTAAGGATACTTCAGTAAACAAAACAGTCCCAAATTCTTCCCCTATGGAGCTTTCTCGGCGAAGGCGGGATTGGTTAGGAGCTGACAATCGGCAGCAGACGATTGTAAATGACCGGACCTTTTTTCTATTCTCCTGCCCAGCCCCCGGCCCGGCCTCCGCCTCCGGCCCTGCTCCAGCCCCGCCAGCGGCCCAGGACCCGCCCCTGGCTCCGGCCCCGCCCCTGGCTCCGCCCCCGCCCCCGCGCCGGCGGCGGCGCGGCGCCCGCGCTTCCGTATCGCTCCTCGTAGGCCGGGGCTCGGCGCGCGCACCCGCACTAAAGACGCTTCTTCCCGGCGGGTAGGAATCCCGCCGGCGAGCCGAACAGTTCCCCGAGCGCAGCCCGCGGACCACCACCCGGCCGCACGGGCCGCTTTTGTCCCCCGCCCGCCGCTTCTGTCCGAGAGGCCGCCCGCGAGGCGCATCCTGACCGCGAGCGTCGGGTCCCAGAGCCGGGCGCGGCTGGGGCCCGAGGCTAGCATCTCTCGGGAGCCGCAAGGCGAGAGCTGCAAAGGTAACGCAGCGTGGCGGGGTCGCGGGAGCGGAGCGCGTGGCCAGCTGACTGGAGGGAAAACGCCGCCTCCCTGCAGCGGTTCCCGGAATCCCCTCCGGTTCCCTCTCGCTCTCCCCGACTCCTCCTCCTCCTCCTGCCCTCCCTCTGCGT",
    "irf4_prom": "GCTCACTGCAACTTCAGCCTCCCGGGTTCAAGCGATTCTCGTGGCTCGTCCTCTCAAGTAGCTGGGGCCACGCCCGGCTAATTTTTGTATTTTTAGTAGAGATGGGGTTTCACCGTGTTGGCCAGGCTGGTCTCGAACTCCTGACCTCAGGCGATCCACCGCCTCGGCCTCCCAAAGTGCTGGGATTACAGGCTTGAGCCACAGCGCCTGGCCTATTTTGGGCTTTTATACCCCACTGGTAAACTGCTTTCCTCCAGGTTGAGGTTAAAACGACATCATTTTAAGGTGAACTGAAGTCTGGAAGTGATTAAGCACTTGGATCCTTAGGGAGCCTCTCCCCGCCCCCATCTCTTTCATGCTAAGATAATTAAAACTTCGGGGCCGGGGCATTGTCTGAGTCACTTCAATTCACCAGCCTAATAGATGCAAAAGGATGTAAGCATGTCAGACACGCAGAGACAGTATTTGAATCAAGCTTAATAGCTCAAGGGAGCTGGGCCATTTCCTATTTTCTTTTTAGTGAGTGCGATGTTCTCTAAACACCGCGGAGAGGCAGGGTTCCCGGTGATGGCCTTGCCGAGGGTGCTCCCGCAACCTCCACCTCCAGTTCTCTTTGGACCATTCCTCCGTCTTCCGTTACACGCTCTGCAAAGCGAAGTCCCCTTCGCACCAGATTCCCGCTACTACACGCCCCCCATTTCCCGCCCTGGCCACATCGCTGCAGTTTAGTGATTGACTGGCCTCCTGAGGTCCTGGCGCAAAGGCGAGATTCGCATTTCGCACCTCGCCCTTCGCGGGAAACGGCCCCAGTGACAGTCCCCGAAGCGGCGCGCGCCCGGCTGGAGGTGCGCTCTCCGGGCGCGGCGCGCGGAGGGTCGCCAAGGGCGCGGGAACCCCACCCCGGCCGCGGCAGCCCCCAGCCTTCACGCCGGCCCTGAGGCTCGCCCGCCCGGCCGGCCCCGGCTCTCGGCTTGCAAAGTCCCTCTCCCCAGTCCAACCCCCGGCCCCCACAGGCCTCGGCGCCCCGCCCCGCCCCAGGCCCCGCCCCAGAGAGTTCTATAAAGTTCCTCTTTCCCACCTCGCACTCTCAGTTTCACCGCTCGATCTTGGGACCCACCGCTGCCCTCAGCTCCGAGTCCAGGGCGAGGTAAGGGCTGGAGTCGGGCAGGAGGAGGGGTGTGAGGCTGATACCAGAGAGGACCCGGAGCGCGAACCAGAGGTTCGACCTCCAGGGCAGCGCAGGGTACCCCGGCTTCGGAGCGGGAAGGGAGCGCGCCCCGTCCTGGAGCTCCGACTCCCACCCCATCTGCGCTGAGCCGGAGGCGCTGGTTTGGGCTCCAAGGCCCGCCTCCTTGGCTCTGCCCGAGCCTCCCCGCCTGCCCTCCGCGCTCCTGCGACGGGGTCGCCACAAGCTGGACGGGATGAGCTAACCGGACTGTCGGGGCCCCAGGAGTGGCTGAGGCGGGGCCGTCCAAGGCACCCACACAAGACGGCACAACTGCCTGCGAGAAACAGGCCCGGCCCTGTGGACCCCAATCCGAGGCTCCTTCCCCTGCTCTTCGTTCCTAAGGGGCCCAAGCTCACGGCGGCCTCCGGCGCGGTGCTCACCCGCTGGCGCAGGAGGAGGAGGAGCTCCACATTTGGGTCGCTCCGAGCCTTGCGTGCGGTGGCCTAGCCGGCCTGGCGCGGTCCCTGCCTCCCAGGCTCCGCAGCTGTCGTCGCCCTCTCCCGCGCCCTCCCCGCCTCCGCTCTCCCGGGCCTGCTCCGGGGTCCGGCGGACGCTCTGCGCGCGGAATCCCCCGTACTGGGGCTGCAGCCCCCGCGTCTGCGCCACTTGTCGTTTGCAGAGCCCACTTAGTGCGCGCTAGCTGGGCAGGGATAGGGGTCCTATTCGGGGCGAAGGGTCTGGATGCGAGCAGAGAAAGCGGAGGGTGGAGGAACCCGGGGCTGCGCCCCTGGAACGCCCGGCCGCAGGCGAGGTCCTCCGCGCGTGGAGGCCGCCAGGGGAGTGGAAACTGACAGAGTCGCGGGGAAGGGGCGAGAAGCGGGTTGGGAGTGAGCGAAGGCAAGCGAGAGCTGCGAGTGAGTGCGGAAGGAGGGCCAGGAGGGGTGGC",
    "irf7_prom": "GGCTACAGGTGTGACTGCAGGTGTGGCCGGCGCGCACACATGAAGTCACAGGTGTTGAACCAGTGTCCAGGCCTGGCGGGAAGGCGCAGGCCGGACCCTGCGGAGACGGGAAAGGCGACGTCAGGGGCGGGTCAGGCTCCCGGGAAAGCGAAACCTAAACAGTGGCGCTTCGCACCCTCCTCGATCCCACCCCGTCCGGTTCTCAGCTCCGCGGAACCCCGCCTCCGCCTCCGCCTCCCTCCCCGCCCGACCCTCATCTCTCAGGCTCCCCCAGCTCTTGGCTCTACCCCTCCGGGGTCACGGAGCCCCCACGGAGGCTCTCGCTCCCGGCCTGCACCGCGTGGGTCTGGGGTCCCCAGTACCTGGGTGCCAGAGCCGCCGGGACGGGAAGTTTCGTCTCGCGGGGAAGCGGAGGGCCGGCGCTTTTATGGTGGCCAGGCGGGAGTTTCCGGGAAGGGCGCGCGCCGCCTGTTCTTATTATTGGATGCGACCAGCGGAACCCCGCCCCGGCCAGCGCGGAGTAGGGAGGAGTGGAGGGCGTTGGGAGTGGCTGCAGTGAGCCGAGATGGAGCCACTCCACTACAGCCCAGGGGACAGAGCAAGACTCAGTCTCAAAAAAAAAAGGAAGTGGGTAATGGGAGGTGGACGTGCCTCGAAAAAGGGGCAGCTGCACCGTTTGCGTTTCTTTTTTTGAGATGGAGTTTCGCTTTTGTTACCCAGGCTGGAGTGCGGTGGCACAATCTTGGCCCACCACAACCTCCGCCTCCCGGGTTCAAGTGATTCTCCTACCTAAGCCTCCCGAGTAGCTGGGATTACAGGCATGAACCACCACGCCCGGCTAATTTTGTATTTTTAGTAGAGACGGGGTTTCTCTATGTTGGTCAGGCTGGTGTCGAACTCCCGACCTCAGGTGATCTGCCCACCTCGGCCTCCCAAAGTGCTGGGATTTAGGCGAGAGCCGCCGTGCGCAGCCCCCTTTGGGTTTTTTACATTGTTCAGT",
}
name = "irf7_prom"
sequence = sequences[name]
seq = (
    sequence[(len(sequence) - 1000) // 2 : -((len(sequence) - 1000) // 2)]
    if len(sequence) > 1000
    else sequence
)
alphabet = ["A", "C", "G", "T"]
x = squid.utils.seq2oh(seq, alphabet)

# define mutagenesis window for sequence
# 500-600 for IFNAR2
# 310-410 for INTS6
# 460-540 for IRF4
# 390-510 for IRF7
mut_windows = {
    "ifnar2_prom": [480, 580],
    "ints6_prom": [310, 410],
    "irf4_prom": [460, 540],
    "irf7_prom": [390, 510],
}
mut_window = mut_windows[name]
seq_length = x.shape[0]

# set up predictor class for in silico MAVE
pred_generator = squid.predictor.ProfilePredictor(
    pred_fun=models,
    batch_size=512,
    task_idx=0,
    reduce_fun=squid.predictor.profile_sum,
)

# set up mutagenizer class for in silico MAVE
mut_generator = squid.mutagenizer.RandomMutagenesis(mut_rate=0.1, uniform=False)

# generate in silico MAVE
mave = squid.mave.InSilicoMAVE(
    mut_generator, pred_generator, seq_length, mut_window=mut_window
)
x_mut, y_mut = mave.generate(x, num_sim=100_000)
tf.keras.backend.clear_session()

# plot histogram of transformed deepnet predictions
fig = squid.impress.plot_y_hist(y_mut)
fig.savefig(f"{name}_quantity_mave_predictions.pdf")

# delimit sequence to region of interest (required for pairwise computational constraints)
x_mut_trim = x_mut[:, mut_window[0] : mut_window[1], :]

# choose surrogate model type
gpmap = "additive"  # {'additive', 'pairwise' if MAVE-NN}

for linearity in ["linear", "nonlinear"]:
    # Construct MAVE-NN model
    surrogate_model = squid.surrogate_zoo.SurrogateMAVENN(
        x_mut_trim.shape,
        num_tasks=y_mut.shape[1],
        gpmap=gpmap,
        regression_type="GE",
        linearity=linearity,
        noise="SkewedT",
        noise_order=2,
        reg_strength=0.1,
        alphabet=alphabet,
        deduplicate=True,
        gpu=True,
    )
    # train surrogate model
    surrogate, mave_df = surrogate_model.train(
        x_mut_trim,
        y_mut,
        learning_rate=5e-4,
        epochs=500,
        batch_size=100,
        early_stopping=True,
        patience=25,
        restore_best_weights=True,
        save_dir=None,
        verbose=1,
    )
    tf.keras.backend.clear_session()
    # retrieve model parameters
    params = surrogate_model.get_params(gauge="empirical")
    # Save surrogate model and mave_df
    surrogate.save(f"{name}_quantity_{linearity}_mave_nn_additive")
    mave_df.to_csv(f"{name}_quantity_{linearity}_mave_nn_additive.csv.gz")
    # plot additive logo
    fig = squid.impress.plot_additive_logo(
        params[1], center=True, view_window=None, alphabet=alphabet, fig_size=[10, 2.5]
    )
    fig.savefig(f"{name}_quantity_{linearity}_additive_only.pdf")
    # Save params
    np.savez_compressed(f"{name}_quantity_{linearity}_mave_nn_additive.npz", *params)

# load surrogate model and mave_df (reload session to avoid VRAM overflow)
for name in ["ifnar2_prom", "ints6_prom", "irf4_prom", "irf7_prom"]:
    for linearity in ["linear", "nonlinear"]:
        # load surrogate model and mave_df
        surrogate = mavenn.load(f"{name}_quantity_{linearity}_mave_nn_additive")
        mave_df = pd.read_csv(
            f"{name}_quantity_{linearity}_mave_nn_additive.csv.gz", index_col=0
        )
        trainval_df, test_df = mavenn.split_dataset(mave_df)
        # plot mavenn y versus yhat
        fig = squid.impress.plot_y_vs_yhat(surrogate, mave_df=mave_df)
        fig.savefig(f"{name}_quantity_{linearity}_mave_nn_additive_y_vs_yhat.pdf")
        # plot mavenn y versus phi
        fig = squid.impress.plot_y_vs_phi(surrogate, mave_df=mave_df)
        fig.savefig(f"{name}_quantity_{linearity}_mave_nn_additive_y_vs_phi.pdf")
